:sectnums!:

[appendix]
= Object store implementations

== The ObjectStore

This appendix examines the various ArjunaCore object store implementations and gives guidelines for creating other implementations and plugging into an application.

This release of {productName} contains several different implementations of a basic object store.
Each serves a particular purpose and is generally optimized for that purpose.
Each of the implementations implements the `ObjectStoreAPI` interface, which defines the minimum operations which must be provided for an object store implementation to be used by the Transaction Service.
You can override the default object store implementation at runtime by setting the `com.arjuna.ats.arjuna.objectstore.objectStoreType` property variable to one of the types described below.

.Class `StateStatus`
[source,java]
----
include::{projectSourceDir}/appendix/extras/appendix_StateStatus.java[]
----


{productName} programmers do not usually need to interact with any of the object store implementations directly, apart from possibly creating them in the first place.
Even this is not necessary if the default store type is used, since {productName} creates stores as necessary.
All stores manipulate instances of the class `ObjectState`.
These instances are named using a `type` (via the object's `type()` operation) and a [path]_Uid_ .

For atomic actions purposes, object states in the store can be principally in two distinct states: `OS_COMMITTED` or `OS_UNCOMMITTED`.
An object state starts in the `OS_COMMITTED` state, but when it is modified under the control of an atomic action, a new second object state may be written that is in the `OS_UNCOMMITTED` state.
If the action commits, this second object state replaces the original and becomes `OS_COMMITTED`.
If the action aborts, this second object state is discarded.
All of the implementations provided with this release handle these state transitions by making use of shadow copies of object states.
However, any other implementation that maintains this abstraction is permissible.

Object states may become hidden, and thus inaccessible, under the control of the crash recovery system.

You can browse the contents of a store through the `allTypes` and `allObjUids` operations. `allTypes` returns an `InputObjectState` containing all of the type names of all objects in a store, terminated by a `null` name.
`allObjUids` returns an `InputObjectState` containing all of the `Uids` of all objects of a given type, terminated by the special `Uid.nullUid()`.

=== Persistent object stores

This section briefly describes the characteristics and optimizations of each of the supplied implementations of the persistent object store.
Persistent object states are mapped onto the structure of the file system supported by the host operating system.

==== Common functionality

In addition to the features mentioned earlier, all of the supplied persistent object stores obey the following rules:

* Each object state is stored in its own file, which is named using the Uid of the object.
* The type of an object, as given by the `type()` operation, determines the directory into which the object is placed.
* All of the stores have a common root directory that is determined when {productName} is configured.
This directory name is automatically prepended to any store-specific root information.
* All stores also have the notion of a localized root directory that is automatically prepended to the type of the object to determine the ultimate directory name.
The localized root name is specified when the store is created.
The default name is `defaultStore`.

[source,text]
----
include::{projectSourceDir}/appendix/extras/default_layout.txt[]
----

==== The shadowing store

The shadowing store is the original version of the object store, which was provided in prior releases.
It is implemented by the class `ShadowingStore`.
It is simple but slow.
It uses pairs of files to represent objects.
One file is the shadow version and the other is the committed version.
Files are opened, locked, operated upon, unlocked, and closed on every interaction with the object store.
This causes a lot of I/O overhead.

If you are overriding the object store implementation, the type of this object store is `ShadowingStore`.

==== No file-level locking

Since transactional objects are concurrency-controlled through `LockManager`, you do not need to impose additional locking at the file level.
The basic ShadowingStore implementation handles file-level locking.
Therefore, the default object store implementation for {productName}, [path]_ShadowNoFileLockStore_, relies upon user-level locking.
This enables it to provide better performance than the [path]_ShadowingStore_ implementation.

If you are overriding the object store implementation, the type of this object store is `ShadowNoFileLockStore`.

==== The hashed store

The HashedStore has the same structure for object states as the ShadowingStore, but has an alternate directory structure that is better suited to storing large numbers of objects of the same type.
Using this store, objects are scattered among a set of directories by applying a hashing function to the object's Uid.
By default, 255 sub-directories are used.
However, you can override this by setting the `ObjectStoreEnvironmentBean.hashedDirectories` environment variable accordingly.

If you are overriding the object store implementation, the type of this object store is `HashedStore`.

==== The JDBC store

The JDBCStore uses a JDBC database to save persistent object states.
When used in conjunction with the Transactional Objects for Java API, nested transaction support is available.
In the current implementation, all object states are stored as [term]_Binary Large Objects (BLOBs)_ within the same table.
The limitation on object state size imposed by using BLOBs is `64k`.
If you try to store an object state which exceeds this limit, an error is generated and the state is not stored.
The transaction is subsequently forced to roll back.

When using the JDBC object store, the application must provide an implementation of the `JDBCAccess` interface, located in the `com.arjuna.ats.arjuna.objectstore` package:

.Interface `JDBCAccess`
[source,java]
----
include::{projectSourceDir}/appendix/extras/jdbcaccess.java[]
----


The implementation of this class is responsible for providing the `Connection` which the JDBC ObjectStore uses to save and restore object states:

`getConnection`::
Returns the Connection to use.
This method is called whenever a connection is required, and the implementation should use whatever policy is necessary for determining what connection to return.
This method need not return the same `Connection` instance more than once.

putConnection::
Returns one of the `Connections` acquired from `getConnection`.
Connections are returned if any errors occur when using them.

initialise::
Used to pass additional arbitrary information to the implementation.

The JDBC object store initially requests the number of `Connections` defined in the `ObjectStoreEnvironmentBean.jdbcPoolSizeInitial` property and will use no more than defined in the `ObjectStoreEnvironmentBean.jdbcPoolSizeMaximum` property.

The implementation of the `JDBCAccess` interface to use should be set in the `ObjectStoreEnvironmentBean.jdbcUserDbAccessClassName` property variable.

If overriding the object store implementation, the type of this object store is `JDBCStore`.

A JDBC object store can be used for managing the transaction log.
In this case, the transaction log implementation should be set to `JDBCActionStore` and the `JDBCAccess` implementation must be provided via the `ObjectStoreEnvironmentBean.jdbcTxDbAccessClassName` property variable.
In this case, the default table name is [path]_JBossTSTxTable_ .

You can use the same `JDBCAccess` implementation for both the user object store and the transaction log.

==== The cached store

This object store uses the hashed object store, but does not read or write states to the persistent backing store immediately.
It maintains the states in a volatile memory cache and either flushes the cache periodically or when it is full.
The failure semantics associated with this object store are different from the normal persistent object stores, because a failure could result in states in the cache being lost.

If overriding the object store implementation, the type of this object store is `CacheStore`.

.Configuration Properties
ObjectStoreEnvironmentBean.cacheStoreHash::
sets the number of internal stores to hash the states over.
The default value is 128.

ObjectStoreEnvironmentBean.cacheStoreSize::
the maximum size the cache can reach before a flush is triggered.
The default is 10240 bytes.

ObjectStoreEnvironmentBean.cacheStoreRemovedItems::
the maximum number of removed items that the cache can contain before a flush is triggered.
By default, calls to remove a state that is in the cache will simply remove the state from the cache, but leave a blank entry (rather than remove the entry immediately, which would affect the performance of the cache).
When triggered, these entries are removed from the cache.
The default value is twice the size of the hash.

ObjectStoreEnvironmentBean.cacheStoreWorkItems::
the maximum number of items that are allowed to build up in the cache before it is flushed.
The default value is 100.
`ObjectStoreEnvironmentBean.cacheStoreScanPeriod` sets the time in milliseconds for periodically flushing the cache.
The default is 120 seconds.

ObjectStoreEnvironmentBean.cacheStoreSync::
determines whether flushes of the cache are sync-ed to disk.
The default is `OFF`.
To enable, set to `ON`.

==== LogStore

This implementation is based on a traditional transaction log.
All transaction states within the same process (VM instance) are written to the same log (file), which is an append-only entity.
When transaction data would normally be deleted, at the end of the transaction, a [path]_delete_ record is added to the log instead.
Therefore, the log just keeps growing.
Periodically a thread runs to prune the log of entries that have been deleted.

A log is initially given a maximum capacity beyond which it cannot grow.
After it reaches this size, the system creates a new log for transactions that could not be accommodated in the original log.
The new log and the old log are pruned as usual.
During the normal execution of the transaction system, there may be an arbitrary number of log instances.
These should be garbage collected by the system,(or the recovery sub-system, eventually.

Check the Configuration Options table for how to configure the LogStore.

:sectnums: